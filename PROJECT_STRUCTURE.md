# Intelligent Web Extractor - Project Structure

This document provides an overview of the Intelligent Web Extractor project structure and architecture.

## ğŸ“ Project Structure

```
intelligent-web-extractor/
â”œâ”€â”€ ğŸ“„ README.md                    # Main project documentation
â”œâ”€â”€ ğŸ“„ pyproject.toml              # Project configuration and dependencies
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ setup.py                    # Installation setup script
â”œâ”€â”€ ğŸ“„ env.example                 # Environment variables template
â”œâ”€â”€ ğŸ“„ example_usage.py            # Usage examples
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md        # This file
â”‚
â”œâ”€â”€ ğŸ“ src/                        # Source code directory
â”‚   â””â”€â”€ ğŸ“ intelligent_web_extractor/
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py         # Package initialization
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ core/               # Core components
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ extractor.py    # Main adaptive extractor
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ semantic_extractor.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ batch_processor.py
â”‚       â”‚   â””â”€â”€ ğŸ“„ custom_extractor.py
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ models/             # Data models
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ extraction_result.py
â”‚       â”‚   â””â”€â”€ ğŸ“„ config.py
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ strategies/         # Extraction strategies
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ semantic_strategy.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ structured_strategy.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ hybrid_strategy.py
â”‚       â”‚   â””â”€â”€ ğŸ“„ rule_based_strategy.py
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ utils/              # Utility components
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ browser_manager.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ ai_client.py
â”‚       â”‚   â””â”€â”€ ğŸ“„ logger.py
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“„ cli.py              # Command line interface
â”‚
â”œâ”€â”€ ğŸ“ tests/                      # Test files
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ test_extractor.py
â”‚   â”œâ”€â”€ ğŸ“„ test_strategies.py
â”‚   â””â”€â”€ ğŸ“„ test_utils.py
â”‚
â”œâ”€â”€ ğŸ“ docs/                       # Documentation
â”‚   â”œâ”€â”€ ğŸ“„ user_guide.md
â”‚   â”œâ”€â”€ ğŸ“„ api_reference.md
â”‚   â””â”€â”€ ğŸ“„ advanced_usage.md
â”‚
â”œâ”€â”€ ğŸ“ examples/                   # Example scripts
â”‚   â”œâ”€â”€ ğŸ“„ basic_extraction.py
â”‚   â”œâ”€â”€ ğŸ“„ batch_processing.py
â”‚   â””â”€â”€ ğŸ“„ custom_rules.py
â”‚
â””â”€â”€ ğŸ“ scripts/                    # Utility scripts
    â”œâ”€â”€ ğŸ“„ install_browsers.py
    â””â”€â”€ ğŸ“„ benchmark.py
```

## ğŸ—ï¸ Architecture Overview

### Core Components

#### 1. **AdaptiveContentExtractor** (`core/extractor.py`)
- Main entry point for content extraction
- Intelligently selects the best extraction strategy
- Manages browser instances and AI clients
- Provides unified interface for all extraction operations

#### 2. **Extraction Strategies** (`strategies/`)
- **SemanticStrategy**: AI-powered content understanding
- **StructuredStrategy**: Data-rich page extraction
- **HybridStrategy**: Combines multiple approaches
- **RuleBasedStrategy**: Custom rule-based extraction

#### 3. **Browser Manager** (`utils/browser_manager.py`)
- Manages Playwright browser instances
- Handles page navigation and content retrieval
- Provides browser lifecycle management
- Supports multiple browser types (Chromium, Firefox, WebKit)

#### 4. **AI Client** (`utils/ai_client.py`)
- Unified interface for AI model interactions
- Supports OpenAI, Anthropic, and local models
- Handles embedding generation and similarity calculations
- Manages API rate limiting and error handling

### Data Models

#### 1. **ExtractionResult** (`models/extraction_result.py`)
- Comprehensive result container
- Includes content, metadata, metrics, and strategy information
- Supports serialization and export formats

#### 2. **ExtractorConfig** (`models/config.py`)
- Centralized configuration management
- Supports environment variables and file-based config
- Validates configuration parameters

### Key Features

#### ğŸ”„ **Adaptive Intelligence**
- Automatically selects the best extraction strategy
- Learns from previous extractions
- Adapts to different website structures

#### ğŸ¯ **Multiple Strategies**
- **Semantic**: AI-powered content understanding
- **Structured**: Data-rich page extraction
- **Hybrid**: Combines multiple approaches
- **Rule-based**: Custom extraction rules

#### âš¡ **High Performance**
- Asynchronous architecture
- Concurrent processing
- Intelligent caching
- Resource optimization

#### ğŸ”§ **Developer Friendly**
- Clean, intuitive API
- Comprehensive documentation
- Extensive configuration options
- Command-line interface

## ğŸš€ Usage Patterns

### Basic Usage
```python
from intelligent_web_extractor import AdaptiveContentExtractor

async with AdaptiveContentExtractor() as extractor:
    result = await extractor.extract_content(
        url="https://example.com",
        user_query="Find pricing information"
    )
    print(result.content)
```

### Batch Processing
```python
from intelligent_web_extractor import BatchProcessor

processor = BatchProcessor()
results = await processor.process_urls([
    "https://site1.com",
    "https://site2.com"
])
```

### Custom Rules
```python
from intelligent_web_extractor import CustomExtractor

extractor = CustomExtractor()
extractor.add_rule("main_content", ".content", "text")
result = await extractor.extract("https://example.com")
```

## ğŸ”§ Configuration

### Environment Variables
- `INTELLIGENT_EXTRACTOR_API_KEY`: Main API key
- `OPENAI_API_KEY`: OpenAI API key
- `ANTHROPIC_API_KEY`: Anthropic API key
- `INTELLIGENT_EXTRACTOR_MODEL_TYPE`: AI model type
- `INTELLIGENT_EXTRACTOR_STRATEGY`: Default strategy

### Configuration File
```yaml
ai_model:
  model_type: openai
  model_name: gpt-4
  temperature: 0.1

browser:
  browser_type: chromium
  headless: true

extraction:
  strategy: adaptive
  confidence_threshold: 0.7
```

## ğŸ§ª Testing

### Running Tests
```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_extractor.py

# Run with coverage
pytest --cov=intelligent_web_extractor
```

### Test Structure
- **Unit Tests**: Test individual components
- **Integration Tests**: Test component interactions
- **Performance Tests**: Test extraction performance
- **Strategy Tests**: Test different extraction strategies

## ğŸ“š Documentation

### User Documentation
- **README.md**: Quick start and basic usage
- **User Guide**: Comprehensive usage guide
- **API Reference**: Complete API documentation
- **Advanced Usage**: Advanced features and techniques

### Developer Documentation
- **Architecture Guide**: System design and architecture
- **Contributing Guide**: How to contribute to the project
- **Development Setup**: Setting up development environment

## ğŸ”„ Development Workflow

### 1. **Setup Development Environment**
```bash
# Clone repository
git clone <repository-url>
cd intelligent-web-extractor

# Install dependencies
pip install -r requirements.txt

# Setup environment
python setup.py
```

### 2. **Running Tests**
```bash
# Run all tests
pytest

# Run specific tests
pytest tests/test_extractor.py -v
```

### 3. **Code Quality**
```bash
# Format code
black src/
isort src/

# Lint code
flake8 src/
mypy src/
```

### 4. **Building Documentation**
```bash
# Build docs
mkdocs build

# Serve docs locally
mkdocs serve
```

## ğŸ¯ Key Design Principles

### 1. **Modularity**
- Each component has a single responsibility
- Clear interfaces between components
- Easy to extend and modify

### 2. **Configurability**
- Extensive configuration options
- Environment variable support
- File-based configuration

### 3. **Performance**
- Asynchronous operations
- Intelligent caching
- Resource optimization

### 4. **Reliability**
- Comprehensive error handling
- Graceful degradation
- Health monitoring

### 5. **Usability**
- Simple, intuitive API
- Comprehensive documentation
- Multiple usage patterns

## ğŸ”® Future Enhancements

### Planned Features
- **Advanced AI Models**: Support for more AI providers
- **Distributed Processing**: Multi-node extraction
- **Real-time Monitoring**: Live extraction monitoring
- **Advanced Caching**: Redis-based caching
- **Plugin System**: Extensible architecture

### Performance Improvements
- **GPU Acceleration**: CUDA support for embeddings
- **Memory Optimization**: Better memory management
- **Concurrent Processing**: Improved parallelism

### Integration Features
- **Database Support**: SQL and NoSQL databases
- **Message Queues**: RabbitMQ and Redis support
- **Cloud Deployment**: Docker and Kubernetes support

This architecture provides a solid foundation for intelligent web content extraction with room for growth and enhancement. 